{"cells":[{"cell_type":"code","execution_count":null,"id":"9c11ee97","metadata":{"id":"9c11ee97"},"outputs":[],"source":["import sys\n","import os\n","import logging\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","import monai\n","from monai.data import ImageDataset\n","from monai.networks.layers.factories import Conv, Dropout, Pool, Norm\n","from monai.transforms import Compose, AddChannel, ScaleIntensity, EnsureType\n","from collections import OrderedDict\n","from typing import Callable, Sequence\n","import math\n","from functools import partial\n","import matplotlib.pyplot as plt\n","\n","pin_memory = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"cf17b2cc","metadata":{"id":"cf17b2cc"},"outputs":[],"source":["class _DenseLayer(nn.Sequential):\n","    def __init__(\n","        self, spatial_dims: int, in_channels: int, growth_rate: int, bn_size: int, dropout_prob: float\n","    ) -> None:\n","        super(_DenseLayer, self).__init__()\n","\n","        out_channels = bn_size * growth_rate\n","        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n","        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n","        dropout_type: Callable = Dropout[Dropout.DROPOUT, spatial_dims]\n","\n","        self.add_module(\"norm1\", norm_type(in_channels))\n","        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n","        self.add_module(\"conv1\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n","\n","        self.add_module(\"norm2\", norm_type(out_channels))\n","        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n","        self.add_module(\"conv2\", conv_type(out_channels, growth_rate, kernel_size=3, padding=1, bias=False))\n","\n","        if dropout_prob > 0:\n","            self.add_module(\"dropout\", dropout_type(dropout_prob))\n","\n","    def forward(self, x):\n","        new_features = super(_DenseLayer, self).forward(x)\n","        return torch.cat([x, new_features], 1)\n","\n","\n","class _DenseBlock(nn.Sequential):\n","    def __init__(\n","        self, spatial_dims: int, layers: int, in_channels: int, bn_size: int, growth_rate: int, dropout_prob: float\n","    ) -> None:\n","        super(_DenseBlock, self).__init__()\n","        for i in range(layers):\n","            layer = _DenseLayer(spatial_dims, in_channels, growth_rate, bn_size, dropout_prob)\n","            in_channels += growth_rate\n","            self.add_module(\"denselayer%d\" % (i + 1), layer)\n","\n","\n","class _Transition(nn.Sequential):\n","    def __init__(self, spatial_dims: int, in_channels: int, out_channels: int) -> None:\n","        super(_Transition, self).__init__()\n","\n","        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n","        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n","        pool_type: Callable = Pool[Pool.AVG, spatial_dims]\n","\n","        self.add_module(\"norm\", norm_type(in_channels))\n","        self.add_module(\"relu\", nn.ReLU(inplace=True))\n","        self.add_module(\"conv\", conv_type(in_channels, out_channels, kernel_size=1, bias=False))\n","        self.add_module(\"pool\", pool_type(kernel_size=2, stride=2))\n","\n","\n","class DenseNet(nn.Module):\n","    \"\"\"\n","    Densenet based on: \"Densely Connected Convolutional Networks\" https://arxiv.org/pdf/1608.06993.pdf\n","    Adapted from PyTorch Hub 2D version:\n","    https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py\n","\n","    Args:\n","        spatial_dims: number of spatial dimensions of the input image.\n","        in_channels: number of the input channel.\n","        out_channels: number of the output classes.\n","        init_features: number of filters in the first convolution layer.\n","        growth_rate: how many filters to add each layer (k in paper).\n","        block_config: how many layers in each pooling block.\n","        bn_size: multiplicative factor for number of bottle neck layers.\n","                      (i.e. bn_size * k features in the bottleneck layer)\n","        dropout_prob: dropout rate after each dense layer.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        spatial_dims: int,\n","        in_channels: int,\n","        out_channels: int,\n","        init_features: int = 64,\n","        growth_rate: int = 32,\n","        block_config: Sequence[int] = (6, 12, 24, 16),\n","        bn_size: int = 4,\n","        dropout_prob: float = 0.0,\n","    ) -> None:\n","\n","        super(DenseNet, self).__init__()\n","\n","        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n","        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n","        pool_type: Callable = Pool[Pool.MAX, spatial_dims]\n","        avg_pool_type: Callable = Pool[Pool.ADAPTIVEAVG, spatial_dims]\n","\n","        self.features = nn.Sequential(\n","            OrderedDict(\n","                [\n","                    (\"conv0\", conv_type(in_channels, init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n","                    (\"norm0\", norm_type(init_features)),\n","                    (\"relu0\", nn.ReLU(inplace=True)),\n","                    (\"pool0\", pool_type(kernel_size=3, stride=2, padding=1)),\n","                ]\n","            )\n","        )\n","\n","        in_channels = init_features\n","        for i, num_layers in enumerate(block_config):\n","            block = _DenseBlock(\n","                spatial_dims=spatial_dims,\n","                layers=num_layers,\n","                in_channels=in_channels,\n","                bn_size=bn_size,\n","                growth_rate=growth_rate,\n","                dropout_prob=dropout_prob,\n","            )\n","            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n","            in_channels += num_layers * growth_rate\n","            if i == len(block_config) - 1:\n","                self.features.add_module(\"norm5\", norm_type(in_channels))\n","            else:\n","                _out_channels = in_channels // 2\n","                trans = _Transition(spatial_dims, in_channels=in_channels, out_channels=_out_channels)\n","                self.features.add_module(\"transition%d\" % (i + 1), trans)\n","                in_channels = _out_channels\n","\n","        # pooling and classification\n","        self.class_layers = nn.Sequential(\n","            OrderedDict(\n","                [\n","                    (\"relu\", nn.ReLU(inplace=True)),\n","                    (\"norm\", avg_pool_type(1)),\n","                    (\"flatten\", nn.Flatten(1)),\n","                    (\"class\", nn.Linear(in_channels, out_channels)),\n","                ]\n","            )\n","        )\n","        '''\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc1 = nn.Linear(1024*4*4*4, 1024)\n","        self.fc2 = nn.Linear(1024, out_channels)\n","\n","        '''\n","        # Avoid Built-in function isinstance was called with the wrong arguments warning\n","        # pytype: disable=wrong-arg-types\n","        for m in self.modules():\n","            if isinstance(m, conv_type):  # type: ignore\n","                nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, norm_type):  # type: ignore\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.constant_(m.bias, 0)\n","        # pytype: enable=wrong-arg-types\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.class_layers(x) # remove if fc1/fc2\n","        #x = torch.flatten(x, 1)\n","        #x = self.fc1(x)\n","        #x = self.fc2(x)\n","        return x\n","\n","\n","def densenet121(**kwargs) -> DenseNet:\n","    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), **kwargs)\n","    return model\n","\n","\n","def densenet169(**kwargs) -> DenseNet:\n","    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 32, 32), **kwargs)\n","    return model\n","\n","\n","def densenet201(**kwargs) -> DenseNet:\n","    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 48, 32), **kwargs)\n","    return model\n","\n","\n","def densenet264(**kwargs) -> DenseNet:\n","    model = DenseNet(init_features=64, growth_rate=32, block_config=(6, 12, 64, 48), **kwargs)\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"dbbb6a15","metadata":{"id":"dbbb6a15"},"outputs":[],"source":["def get_inplanes():\n","    return [64, 128, 256, 512]\n","\n","\n","def conv3x3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv3d(in_planes,\n","                     out_planes,\n","                     kernel_size=3,\n","                     stride=stride,\n","                     padding=1,\n","                     bias=False)\n","\n","\n","def conv1x1x1(in_planes, out_planes, stride=1):\n","    return nn.Conv3d(in_planes,\n","                     out_planes,\n","                     kernel_size=1,\n","                     stride=stride,\n","                     bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, downsample=None):\n","        super().__init__()\n","\n","        self.conv1 = conv3x3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm3d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm3d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1, downsample=None):\n","        super().__init__()\n","\n","        self.conv1 = conv1x1x1(in_planes, planes)\n","        self.bn1 = nn.BatchNorm3d(planes)\n","        self.conv2 = conv3x3x3(planes, planes, stride)\n","        self.bn2 = nn.BatchNorm3d(planes)\n","        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n","        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self,\n","                 block,\n","                 layers,\n","                 block_inplanes,\n","                 n_input_channels=3,\n","                 conv1_t_size=7,\n","                 conv1_t_stride=1,\n","                 no_max_pool=False,\n","                 shortcut_type='B',\n","                 widen_factor=1.0,\n","                 n_classes=400):\n","        super().__init__()\n","\n","        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n","\n","        self.in_planes = block_inplanes[0]\n","        self.no_max_pool = no_max_pool\n","\n","        self.conv1 = nn.Conv3d(n_input_channels,\n","                               self.in_planes,\n","                               kernel_size=(conv1_t_size, 7, 7),\n","                               stride=(conv1_t_stride, 2, 2),\n","                               padding=(conv1_t_size // 2, 3, 3),\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm3d(self.in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n","                                       shortcut_type)\n","        self.layer2 = self._make_layer(block,\n","                                       block_inplanes[1],\n","                                       layers[1],\n","                                       shortcut_type,\n","                                       stride=2)\n","        self.layer3 = self._make_layer(block,\n","                                       block_inplanes[2],\n","                                       layers[2],\n","                                       shortcut_type,\n","                                       stride=2)\n","        self.layer4 = self._make_layer(block,\n","                                       block_inplanes[3],\n","                                       layers[3],\n","                                       shortcut_type,\n","                                       stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n","        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv3d):\n","                nn.init.kaiming_normal_(m.weight,\n","                                        mode='fan_out',\n","                                        nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm3d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _downsample_basic_block(self, x, planes, stride):\n","        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n","        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n","                                out.size(3), out.size(4))\n","        if isinstance(out.data, torch.cuda.FloatTensor):\n","            zero_pads = zero_pads.cuda()\n","\n","        out = torch.cat([out.data, zero_pads], dim=1)\n","\n","        return out\n","\n","    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_planes != planes * block.expansion:\n","            if shortcut_type == 'A':\n","                downsample = partial(self._downsample_basic_block,\n","                                     planes=planes * block.expansion,\n","                                     stride=stride)\n","            else:\n","                downsample = nn.Sequential(\n","                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n","                    nn.BatchNorm3d(planes * block.expansion))\n","\n","        layers = []\n","        layers.append(\n","            block(in_planes=self.in_planes,\n","                  planes=planes,\n","                  stride=stride,\n","                  downsample=downsample))\n","        self.in_planes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.in_planes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        if not self.no_max_pool:\n","            x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","def generate_model(model_depth, **kwargs):\n","    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n","\n","    if model_depth == 10:\n","        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n","    elif model_depth == 18:\n","        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n","    elif model_depth == 34:\n","        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n","    elif model_depth == 50:\n","        model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n","    elif model_depth == 101:\n","        model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n","    elif model_depth == 152:\n","        model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n","    elif model_depth == 200:\n","        model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"f86b68b2","metadata":{"id":"f86b68b2","outputId":"738915ce-8a68-4ffa-82b2-983b08ed1318"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","tensor([115.,  88.,  87.,  96., 100., 119., 113., 104., 127.,  98.,  92., 113.,\n","        113., 145., 107., 180., 111., 129., 111.,  88., 106., 119., 121., 106.,\n","        129., 129., 126., 126.,  94., 121., 135., 136.,  91., 107., 118.,  87.,\n","        108., 113.,  89., 149., 115., 126., 102., 111., 118.,  67.,  99., 119.,\n","        101.,  98., 111., 129.,  99., 111., 106., 125.,  99., 108., 102., 101.,\n","        113., 118., 113.,  78., 112.,  99., 124.,  84., 108., 117., 118., 121.,\n","        109., 127., 100.,  98., 129., 107., 131., 103., 121., 102., 121.,  93.,\n","         98., 109.,  83., 101., 116., 123., 121.,  97.,  94., 104.,  86., 125.,\n","        108., 106.,  97., 119., 107.,  88.,  98.,  81., 126., 106., 106.,  95.,\n","         72.,  96.,  91., 121.,  85.,  90., 133., 108., 119., 112., 136., 120.,\n","         98., 123., 126.,  93., 139., 115.,  98.,  98.,  95.,  99., 102.,  98.,\n","        115., 116., 115., 106., 113.,  90., 103., 117., 106.,  99.,  96.,  99.,\n","        108., 130.,  98., 116.,  87., 132., 108., 140., 107., 109.,  76., 114.,\n","         99.,  89., 136., 105., 115., 116., 111., 118.,  96., 113.,  98.,  94.,\n","        127., 108.])\n","resnet50\n"]}],"source":["data_dir = '/home/marafath/scratch/abide_iq_combined'\n","\n","np.random.seed(42)\n","idx = np.random.permutation(850)\n","\n","# options\n","im_type = 'int'  #'rav', 'int_rav'\n","fold = 0 # 0-4\n","iq = 'viq' # 'all', 'viq', 'fiq'\n","iq_type = 'absolute' # 'residual'\n","arch = 'resnet50' #'resnet', resnet50, densenet, densenet169\n","win_size = (140, 175, 130)\n","\n","\n","if im_type == 'int':\n","    datalist = os.listdir(os.path.join(data_dir, \"int\"))\n","    data_dir2 = os.path.join(data_dir, \"int\")\n","elif im_type == 'rav':\n","    datalist = os.listdir(os.path.join(data_dir, \"rav\"))\n","    data_dir2 = os.path.join(data_dir, \"rav\")\n","elif im_type == 'int_rav':\n","    datalist = os.listdir(os.path.join(data_dir, \"int_rav\"))\n","    data_dir2 = os.path.join(data_dir, \"int_rav\")\n","\n","\n","train_image = []\n","train_label = []\n","validation_image = []\n","validation_label = []\n","\n","start = fold*170\n","end = (fold+1)*170\n","\n","for i in range(len(datalist)):\n","    nifti_name = datalist[idx[i]]\n","    if iq == 'all':\n","        if iq_type == 'absolute':\n","            iq_label = [float(nifti_name.split('_')[2]), float(nifti_name.split('_')[6]), float(nifti_name.split('_')[10])]\n","        else:\n","            iq_label = [float(nifti_name.split('_')[4]), float(nifti_name.split('_')[8]), float(nifti_name.split('_')[12])]\n","        no_out_classes = 3\n","    elif iq == 'fiq':\n","        if iq_type == 'absolute':\n","            iq_label = float(nifti_name.split('_')[2])\n","        else:\n","            iq_label = float(nifti_name.split('_')[4])\n","        no_out_classes = 1\n","    elif iq == 'viq':\n","        if iq_type == 'absolute':\n","            iq_label = float(nifti_name.split('_')[6])\n","        else:\n","            iq_label = float(nifti_name.split('_')[8])\n","        no_out_classes = 1\n","    elif iq == 'piq':\n","        if iq_type == 'absolute':\n","            iq_label = float(nifti_name.split('_')[10])\n","        else:\n","            iq_label = float(nifti_name.split('_')[12])\n","        no_out_classes = 1\n","\n","    if i >= start and i < end:\n","        validation_image.append(os.path.join(data_dir2, nifti_name))\n","        validation_label.append(iq_label)\n","    else:\n","        train_image.append(os.path.join(data_dir2, nifti_name))\n","        train_label.append(iq_label)\n","\n","train_label = torch.tensor(train_label)\n","validation_label = torch.tensor(validation_label)\n","\n","print(no_out_classes)\n","print(validation_label)\n","print(arch)\n","\n","# Define transforms\n","train_transforms = Compose([ScaleIntensity(), AddChannel(), EnsureType()])\n","val_transforms = Compose([ScaleIntensity(), AddChannel(), EnsureType()])\n","\n","# create a training data loader\n","train_ds = ImageDataset(image_files=train_image, labels=train_label, transform=train_transforms)\n","train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=1, pin_memory=pin_memory)\n","\n","# create a validation data loader\n","val_ds = ImageDataset(image_files=validation_image, labels=validation_label, transform=val_transforms)\n","val_loader = DataLoader(val_ds, batch_size=1, num_workers=1, pin_memory=pin_memory)\n","\n","# Create DenseNet121/ResNet18, MSELoss and Adam optimizer\n","if arch == 'densenet169':\n","    model = densenet169(spatial_dims=3, in_channels=1, out_channels=no_out_classes).to(device)\n","if arch == 'densenet':\n","    model = densenet121(spatial_dims=3, in_channels=1, out_channels=no_out_classes).to(device)\n","elif arch == 'resnet50':\n","    model = generate_model(model_depth=50, n_input_channels=1, n_classes=no_out_classes, shortcut_type='B').to(device)\n","elif arch == 'resnet':\n","    model = generate_model(model_depth=18, n_input_channels=1, n_classes=no_out_classes, shortcut_type='B').to(device)\n"]},{"cell_type":"code","execution_count":null,"id":"8387b709","metadata":{"id":"8387b709"},"outputs":[],"source":["model.load_state_dict(torch.load(f'/home/marafath/scratch/abide_saved_models/{im_type}_{arch}_{iq}_{iq_type}_f{fold}.pth'))\n","model.eval()\n","#cam = monai.visualize.GradCAM(nn_module=model, target_layers=\"class_layers.relu\") # for densenet121 and densenet169\n","cam = monai.visualize.GradCAM(nn_module=model, target_layers=\"layer4.2\") # for Resnet50\n","#cam = monai.visualize.GradCAM(nn_module=model, target_layers=\"layer4.1\") # for Resnet18"]},{"cell_type":"code","execution_count":null,"id":"b004f678","metadata":{"id":"b004f678"},"outputs":[],"source":["for name, param in model.named_modules(): print(name, param)"]},{"cell_type":"code","execution_count":null,"id":"7cbe44ee","metadata":{"id":"7cbe44ee"},"outputs":[],"source":["from torchsummary import summary\n","summary(model.cuda(), (1, 140, 175, 130))"]},{"cell_type":"code","execution_count":null,"id":"28b9d410","metadata":{"id":"28b9d410"},"outputs":[],"source":["import nibabel as nib\n","count = 0\n","for val_data in val_loader:\n","    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n","    im = val_images.cpu().detach().numpy()\n","    cam_result = cam(x=val_images, class_idx=None)\n","    c = cam_result.cpu().detach().numpy()\n","    im1 = im.squeeze(0).squeeze(0)\n","    c1 = c.squeeze(0).squeeze(0)\n","\n","\n","    im1 = nib.Nifti1Image(im1, np.eye(4))\n","    nib.save(im1, f'/home/marafath/scratch/im_gradcam/{im_type}_{arch}_{iq}_{iq_type}_f{fold}_image_{count}.nii.gz')\n","\n","    c1 = nib.Nifti1Image(c1, np.eye(4))\n","    nib.save(c1, f'/home/marafath/scratch/im_gradcam/{im_type}_{arch}_{iq}_{iq_type}_f{fold}_gradcam_{count}.nii.gz')\n","\n","    count += 1\n","\n","    '''\n","    plt.figure('check', (18, 6))\n","    plt.subplot(1, 4, 1)\n","    plt.title('CT-65')\n","    plt.imshow(im1[:, :, 65], cmap='gray')\n","    plt.subplot(1, 4, 2)\n","    plt.title('GradCAM')\n","    plt.imshow(c1[:, :, 65])\n","    plt.subplot(1, 4, 3)\n","    plt.title('CT-100')\n","    plt.imshow(im1[:, :, 100], cmap='gray')\n","    plt.subplot(1, 4, 4)\n","    plt.title('GradCAM')\n","    plt.imshow(c1[:, :, 100])\n","    plt.show()\n","    '''\n","\n",""]},{"cell_type":"code","execution_count":null,"id":"d6223d35","metadata":{"id":"d6223d35"},"outputs":[],"source":["import nibabel as nib\n","count = 0\n","for val_data in val_loader:\n","    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n","    im = val_images.cpu().detach().numpy()\n","    cam_result = cam(x=val_images, class_idx=None)\n","    c = cam_result.cpu().detach().numpy()\n","    im1 = im.squeeze(0).squeeze(0)\n","    c1 = c.squeeze(0).squeeze(0)\n","\n","    im11 = im1\n","    im11[im1 > 0] = 1\n","    c11 = c1*im11\n","\n","\n","    im1 = nib.Nifti1Image(im1, np.eye(4))\n","    nib.save(im1, f'/home/marafath/scratch/im_gradcam/{im_type}_{arch}_{iq}_{iq_type}_f{fold}_image_{count}.nii.gz')\n","\n","    c11 = nib.Nifti1Image(c11, np.eye(4))\n","    nib.save(c11, f'/home/marafath/scratch/im_gradcam/{im_type}_{arch}_{iq}_{iq_type}_f{fold}_gradcam_{count}.nii.gz')\n","\n","    count += 1\n","\n","    if count == 2:\n","        break\n","\n","    '''\n","    plt.figure('check', (18, 6))\n","    plt.subplot(1, 4, 1)\n","    plt.title('CT-65')\n","    plt.imshow(im1[:, :, 65], cmap='gray')\n","    plt.subplot(1, 4, 2)\n","    plt.title('GradCAM')\n","    plt.imshow(c1[:, :, 65])\n","    plt.subplot(1, 4, 3)\n","    plt.title('brain mask')\n","    plt.imshow(im11[:, :, 65], cmap='gray')\n","    plt.subplot(1, 4, 4)\n","    plt.title('GradCAM masked')\n","    plt.imshow(c11[:, :, 65])\n","    plt.show()\n","    '''\n",""]},{"cell_type":"code","execution_count":null,"id":"b72b8628","metadata":{"id":"b72b8628","outputId":"a7d0ab4e-6efb-48c6-9603-1cfb0b15b332"},"outputs":[{"name":"stdout","output_type":"stream","text":["original feature shape torch.Size([1, 1, 9, 6, 5])\n","upsampled feature shape [1, 1, 140, 175, 130]\n"]}],"source":["model.load_state_dict(torch.load(f'/home/marafath/scratch/abide_saved_models/{im_type}_{arch}_{iq}_{iq_type}_f{fold}.pth'))\n","model.eval()\n","#for name, _ in model.named_modules(): print(name)\n","cam = monai.visualize.GradCAM(nn_module=model, target_layers=\"layer4.1\")\n","# cam = monai.visualize.GradCAMpp(nn_module=model_3d, target_layers=\"class_layers.relu\")\n","print(\"original feature shape\",cam.feature_map_size([1, 1] + list(win_size), device),)\n","print(\"upsampled feature shape\", [1, 1] + list(win_size))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}